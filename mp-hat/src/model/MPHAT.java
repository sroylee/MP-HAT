package model;

import tool.*;

import java.io.BufferedWriter;
import java.util.Arrays;
import java.util.Random;
import org.apache.commons.math3.distribution.NormalDistribution;
import java.io.File;
import java.io.FileWriter;

public class MPHAT {
	public String datapath;
	public Dataset dataset;
	public int nTopics;
	public int batch;

	// priors

	public double alpha;// prior for users' platform preferences
	public double kappa;// prior for user's topic interests
	public double theta;
	public double sigma;// variance of users' authorities
	public double delta;// variance of users' hubs
	public double gamma; // variance of topic word distribution
	public double epsilon = 0.000001;
	public double lamda = 0.01;

	public Random rand;

	// Gibbs sampling variables
	// user-topic counts
	public int[][] n_zu = null; // n_zu[z][u]: number of times topic z is
								// observed in posts by user u
	public int[] sum_nzu = null; // sum_nzu[u] total number of topics that are
									// observed in posts by user u

	// topic-word counts
	public int[][] n_zw = null; // n_wz[z][w]: number of times word w is
								// generated by topic z in a post
	public int[] sum_nzw = null; // sum_nwz[z]: total number of times words that
									// are generated by topic z in a post

	// topic-word distribution
	public double[][] topicWordDist = null; // topicWordDist[k][w]: the
											// distribution of word w for topic
											// k. Sum of each words distribution
											// for each k = 1

	public double[][] optTopicWordDist = null; // optimized topicWordDist[k][w]
	
	// options for learning
	public double lineSearch_alpha = 0.0001;
	public double lineSearch_beta = 0.1;
	public int lineSearch_MaxIterations = 10;;
	public double lineSearch_lambda;

	public int maxIteration_topicalInterest = 10;
	public int maxIteration_Authorities = 10;
	public int maxIteration_Hubs = 10;

	public int max_GibbsEM_Iterations = 500;
	
	private static Configure.ModelMode mode;

	/***
	 * 
	 * @param _datasetPath
	 * @param _nTopics
	 */
	public MPHAT(String _datasetPath, int _nTopics, int _batch) {
		this.datapath = _datasetPath;
		this.dataset = new Dataset(_datasetPath, _batch, false);
		this.nTopics = _nTopics;
		this.batch = _batch;
		n_zu = new int[nTopics][dataset.nUsers];
		sum_nzu = new int[dataset.nUsers];
		n_zw = new int[nTopics][dataset.vocabulary.length];
		sum_nzw = new int[nTopics];
		topicWordDist = new double[nTopics][dataset.vocabulary.length];
	}

	/***
	 * get likelihood of the whole dataset
	 * 
	 * @return
	 */
	private double getLikelihood() {
		// to be written
		// Compute the likelihood to make sure that it is improving L(text) +
		// L(link)
		// value can be more than 1
		// sum of eqn 1 -10
		return 0;

	}

	/***
	 * compute likelihood of data as a function of topical interest of u when
	 * the interest is x, i.e., if L(data|parameters) = f(X_u) + const-of-X_u
	 * then this function returns f(x)
	 * 
	 * @param u
	 * @return
	 */
	private double getLikelihood_topicalInterest(int u, double[] x) {
		// Refer to Eqn 16 in Learning paper for Formula
		
		double authorityLikelihood = 0;
		double hubLikelihood = 0;
		double postLikelihood = 0;
		double topicLikelihood = 0;
		double finalLikelihood = 0;
		double denominator = 0;

		// Set the current user to be u
		User currUser = dataset.users[u];

		for (int k = 0; k < nTopics; k++) {
			//First term in eqn 16
			hubLikelihood += -((currUser.hubs[k]*delta)/x[k]) - (delta*Math.log(x[k]));
			
			//Second term in eqn 16
			authorityLikelihood += -((currUser.authorities[k]*sigma)/x[k]) - (sigma*Math.log(x[k]));
			
			//Fourth term in eqn 16
			topicLikelihood += ((kappa-1) * Math.log(x[k])) - (x[k]/theta);		
		
			//denominator of third term in eqn 16
			denominator += Math.exp(x[k]);	
		}
		
		for (int i = 0; i < currUser.nPosts; i++) {
			// Only compute post likelihood of posts which are in batch (i.e. training batch = 1)
			if (currUser.postBatches[i] == batch) {
				//Third term in eqn 16
				int postTopic = currUser.posts[i].topic;
				postLikelihood += Math.exp(x[postTopic])/denominator ;
				
			}
		}
		finalLikelihood = authorityLikelihood + hubLikelihood + postLikelihood + topicLikelihood;
		return finalLikelihood;
	}

	/***
	 * compute gradient of likelihood of data with respect to interest of u in
	 * topic k when the interest is x, i.e., if if L(data|parameters) = f(X_u) +
	 * const-of-X_u then this function return df/dX_uk at X_uk = x
	 * 
	 * @param u
	 * @param k
	 * @param x
	 * @return
	 */
	private double gradLikelihood_topicalInterest(int u, int k, double x) {
		// Refer to Eqn 18 in Learning paper
		double authorityLikelihood = 0;
		double hubLikelihood = 0;
		double postLikelihood = 0;
		double topicLikelihood = 0;
		double gradLikelihood = 0;
		
		// Set the current user to be u
		User currUser = dataset.users[u];

		//First term in eqn 18
		hubLikelihood = ((currUser.hubs[k]*delta)/Math.pow(x, 2)) - (delta/x);
		
		//Second term in eqn 18
		authorityLikelihood = ((currUser.authorities[k]*sigma)/Math.pow(x, 2)) - (sigma/x);
		
		//Third term in eqn 18
		double denominator = 0;
		for (int i = 0; i < nTopics; i++) {
			denominator += Math.exp(currUser.topicalInterests[i]);	
		}
		for (int i = 0; i < currUser.nPosts; i++) {
			// Only compute post likelihood of posts which are in batch (i.e. training batch = 1)
			if (currUser.postBatches[i] == batch) {
				// Only consider posts which are assigned topic k (i.e. z_{v,s} = k)
				if (currUser.posts[i].topic == k) {
					//Third term in eqn 18 seems odd. There is a need to compute the denominator which is sum_k
					double sub_term = 0;
					for (int j =0; j < currUser.nPosts; j++){
						sub_term += (1/denominator) * x;
					}
					postLikelihood = 1 - sub_term;
				}
			}
		}
		
		//Fourth term in eqn 18
		topicLikelihood = ((kappa-1)/x) - (1/theta);
		
		gradLikelihood = authorityLikelihood + hubLikelihood + postLikelihood + topicLikelihood;
		
		return gradLikelihood;

	}

	private double[] simplexProjection(double[] x, double z) {
		// this will be replaced by the softmax function
		// Tuan-Anh: yes, this will be removed
		return null;
	}

	/***
	 * alternating step to optimize topical interest of u
	 * 
	 * @param u
	 */
	private void altOptimize_topicalInterest(int u) {

	}

	/***
	 * compute likelihood of data as a function of authority of u when the
	 * authority is x, i.e., if L(data|parameters) = f(A_u) + const-of-A_u then
	 * this function returns f(x)
	 * 
	 * @param v
	 * @param x[]
	 * @return
	 */
	private double getLikelihood_authority(int v, double[] x) {
		// Refer to Eqn 24 in Learning paper
		double followerLikelihood = 0;
		double nonFollowerLikelihood = 0;
		double postLikelihood = 0;
		double likelihood = 0;

		// Set the current user to be v
		User currUser = dataset.users[v];

		// First term in eqn 24. Compute follower likelihood. 
		if (currUser.followers != null) {
			for (int i = 0; i < currUser.followers.length; i++) {
				for (int p = 0; p < Configure.NUM_OF_PLATFORM; p++) {
					int u = currUser.followers[i].followerIndex;
					User follower = dataset.users[u];
					int followerPlatform = currUser.followers[i].platform;
					
					//only consider this user if he exist in the platform
					if (currUser.platforms[p] == 1){
						//only consider follower relationships in the platform
						if (followerPlatform == p){
							// Compute H_u^p * A_v^p
							double HupAvp = 0;
							for (int z = 0; z < nTopics; z++) {
								HupAvp += follower.hubs[z] * follower.topicalPlatformPreference[z][p] * x[z] * follower.topicalPlatformPreference[z][p];// now A_v is x
							}
							HupAvp = HupAvp * lamda;
							double fHupAvp = 2 * ((1 / (Math.exp(-HupAvp) + 1)) - 0.5); 
							followerLikelihood += Math.log(fHupAvp);
						}
					}
				}
			}
		}
		
		// Second term in eqn 24. Compute non follower likelihood. 
		if (currUser.nonFollowers != null) {
			for (int i = 0; i < currUser.nonFollowers.length; i++) {
				for (int p = 0; p < Configure.NUM_OF_PLATFORM; p++) {
					int u = currUser.nonFollowers[i].followerIndex;
					User nonFollower = dataset.users[u];
					int nonFollowerPlatform = currUser.nonFollowers[i].platform;
					
					//only consider this user if he exist in the platform
					if (currUser.platforms[p] == 1){
						//only consider nonfollower relationships in the platform
						if (nonFollowerPlatform == p){
							// Compute H_u * A_v
							double HupAvp = 0;
							for (int z = 0; z < nTopics; z++) {
								HupAvp += nonFollower.hubs[z] * nonFollower.topicalPlatformPreference[z][p] * x[z] * nonFollower.topicalPlatformPreference[z][p];// now A_v is x
							}
							HupAvp = HupAvp * lamda;
							double fHupAvp = 2 * ((1 / (Math.exp(-HupAvp) + 1)) - 0.5);
							nonFollowerLikelihood += Math.log(1 - fHupAvp);
						}
					}
				}
			}
		}
		// Third term in eqn 24. Compute post likelihood.
		for (int k = 0; k < nTopics; k++) {
			postLikelihood += ((sigma-1)*Math.log(x[k])) - ((x[k]*sigma)/currUser.topicalInterests[k]) ;// now A_v is x
		}

		likelihood = nonFollowerLikelihood + followerLikelihood + postLikelihood;
		
		return likelihood;
	}

	/***
	 * compute gradient of likelihood of data with respect to authority of u in
	 * topic k when the authority is x, i.e., if if L(data|parameters) = f(A_u)
	 * + const-of-A_u then this function return df/dA_uk at A_uk = x
	 * 
	 * @param v
	 * @param k
	 * @param x
	 * @return
	 */
	private double gradLikelihood_authority(int v, int k, double x) {
		// Refer to Eqn 26 in Learning paper
		double followerLikelihood = 0;
		double nonFollowerLikelihood = 0;
		double postLikelihood = 0;
		double gradLikelihood = 0;

		// Set the current user to be v
		User currUser = dataset.users[v];
		
		// First term in eqn 26. Compute follower likelihood
		if (currUser.followers != null) {
			for (int i = 0; i < currUser.followers.length; i++) {
				for (int p = 0; p < Configure.NUM_OF_PLATFORM; p++) {
					int u = currUser.followers[i].followerIndex;
					User follower = dataset.users[u];
					int followerPlatform = currUser.followers[i].platform;
					
					//only consider this user if he exist in the platform and the follower relationship is in this platform
					if (currUser.platforms[p] == 1 && followerPlatform == p){
						// something looks strange for eqn 26
						
					} 
				}
			}
		}		

		postLikelihood = ((Math.log(x) - currUser.topicalInterests[k]) / Math.pow(sigma, 2)) * (1 / x);

		gradLikelihood = nonFollowerLikelihood + followerLikelihood - postLikelihood;

		return gradLikelihood;
	}

	/***
	 * alternating step to optimize authorities of user u
	 * 
	 * @param u
	 */
	private void altOptimize_Authorities(int u) {

	}

	/***
	 * compute likelihood of data as a function of hub of u when the hub is x,
	 * i.e., if L(data|parameters) = f(H_u) + const-of-H_u then this function
	 * returns f(x)
	 * 
	 * @param u
	 * @param x[]
	 * @return
	 */
	private double getLikelihood_hub(int u, double[] x) {
		// Refer to Eqn 20 in learning paper
		double followingLikelihood = 0;
		double nonFollowingLikelihood = 0;
		double postLikelihood = 0;
		double likelihood = 0;

		// Set the current user to be v
		User currUser = dataset.users[u];

		// First term in eqn 20. Compute following likelihood. 
		if (currUser.followings != null) {
			for (int i = 0; i < currUser.followings.length; i++) {
				for (int p = 0; p < Configure.NUM_OF_PLATFORM; p++) {
					int v = currUser.followings[i].followingIndex;
					User following = dataset.users[v];
					int followingPlatform = currUser.followings[i].platform;
					
					//only consider this user if he exist in the platform
					if (currUser.platforms[p] == 1){
						//only consider follower relationships in the platform
						if (followingPlatform == p){
							// Compute H_u^p * A_v^p
							double HupAvp = 0;
							for (int z = 0; z < nTopics; z++) {
								HupAvp += x[z] * following.topicalPlatformPreference[z][p] * following.authorities[z] * following.topicalPlatformPreference[z][p];// now H_u is x
							}
							HupAvp = HupAvp * lamda;
							double fHupAvp = 2 * ((1 / (Math.exp(-HupAvp) + 1)) - 0.5); 
							followingLikelihood += Math.log(fHupAvp);
						}
					}
				}
			}
		}
		
		// Second term in eqn 20. Compute non following likelihood. 
		if (currUser.nonFollowings != null) {
			for (int i = 0; i < currUser.nonFollowings.length; i++) {
				for (int p = 0; p < Configure.NUM_OF_PLATFORM; p++) {
					int v = currUser.nonFollowings[i].followingIndex;
					User nonFollowing = dataset.users[v];
					int nonFollowingPlatform = currUser.nonFollowings[i].platform;
					
					//only consider this user if he exist in the platform
					if (currUser.platforms[p] == 1){
						//only consider nonfollowing relationships in the platform
						if (nonFollowingPlatform == p){
							// Compute H_u * A_v
							double HupAvp = 0;
							for (int z = 0; z < nTopics; z++) {
								HupAvp += x[z] * nonFollowing.topicalPlatformPreference[z][p] * nonFollowing.authorities[z] * nonFollowing.topicalPlatformPreference[z][p];// now H_u is x
							}
							HupAvp = HupAvp * lamda;
							double fHupAvp = 2 * ((1 / (Math.exp(-HupAvp) + 1)) - 0.5);
							nonFollowingLikelihood += Math.log(1 - fHupAvp);
						}
					}
				}
			}
		}
		// Third term in eqn 20. Compute post likelihood.
		for (int k = 0; k < nTopics; k++) {
			postLikelihood += ((delta-1)*Math.log(x[k])) - ((x[k]*delta)/currUser.topicalInterests[k]) ;// now H_u is x
		}

		likelihood = nonFollowingLikelihood + followingLikelihood + postLikelihood;
		
		return likelihood;
	}

	/***
	 * compute gradient of likelihood of data with respect to hub of u in topic
	 * k when the hub is x, i.e., if if L(data|parameters) = f(H_u) +
	 * const-of-H_u then this function return df/dH_uk at H_uk = x
	 * 
	 * @param u
	 * @param k
	 * @param x
	 * @return
	 */
	private double gradLikelihood_hub(int u, int k, double x) {
		// Refer to Eqn 22 in learning paper
		return 0;
	}

	/***
	 * alternating step to optimize hubs of user u
	 * 
	 * @param u
	 */
	private void altOptimize_Hubs(int u) {

	}

	/***
	 * alternating step to optimize topics' word distribution
	 */
	private void altOptimize_topics() {

	}

	/***
	 * to sample topic for post n of user u
	 * 
	 * @param u
	 * @param n
	 */
	private void sampleTopic(int u, int n) {
		// Are we still using gib sampling for this?
		// How about the platform selection for the post?
		// Tuan-Anh: yes, we use gibbs samling for this
		// Tuan-Anh: refer to Equation 31 in
	}
	
	/***
	 * compute likelihood of data as a function of platform preference for topic
	 * k of u when the preference is x, i.e., if L(data|parameters) = f(Eta_uk)
	 * + const-of-Eta_uk then this function returns f(x)
	 * 
	 * @param u
	 * @return
	 */
	private double getLikelihood_platformPreference(int u, double[][] x) {
		// Refer to Eqn 28 in Learning paper for Formula
		double linkLikelihood = 0;
		double nonLinkLikelihood = 0;
		double postLikelihood = 0;
		double platformLikelihood = 0;
		double likelihood = 0;

		// Set the current user to be v
		User currUser = dataset.users[u];

		// First term in eqn 28. Compute link likelihood. 
		if (currUser.followings != null) {
			for (int i = 0; i < currUser.followings.length; i++) {
				for (int p = 0; p < Configure.NUM_OF_PLATFORM; p++) {
					int v = currUser.followings[i].followingIndex;
					User following = dataset.users[v];
					int followingPlatform = currUser.followings[i].platform;
					
					//only consider this user if he exist in the platform
					if (currUser.platforms[p] == 1){
						//only consider follower relationships in the platform
						if (followingPlatform == p){
							// Compute H_u^p * A_v^p
							double HupAvp = 0;
							for (int z = 0; z < nTopics; z++) {
								HupAvp += currUser.hubs[z] * x[z][p] * following.authorities[z] * x[z][p];// now Eta_u,k is x
							}
							HupAvp = HupAvp * lamda;
							double fHupAvp = 2 * ((1 / (Math.exp(-HupAvp) + 1)) - 0.5); 
							linkLikelihood += Math.log(fHupAvp);
						}
					}
				}
			}
		}
		if (currUser.followers != null) {
			for (int i = 0; i < currUser.followers.length; i++) {
				for (int p = 0; p < Configure.NUM_OF_PLATFORM; p++) {
					int v = currUser.followers[i].followerIndex;
					User follower = dataset.users[v];
					int followerPlatform = currUser.followers[i].platform;
					
					//only consider this user if he exist in the platform
					if (currUser.platforms[p] == 1){
						//only consider follower relationships in the platform
						if (followerPlatform == p){
							// Compute H_u^p * A_v^p
							double HupAvp = 0;
							for (int z = 0; z < nTopics; z++) {
								HupAvp += follower.hubs[z] * x[z][p] * currUser.authorities[z] * x[z][p];// now Eta_u,k is x
							}
							HupAvp = HupAvp * lamda;
							double fHupAvp = 2 * ((1 / (Math.exp(-HupAvp) + 1)) - 0.5); 
							linkLikelihood += Math.log(fHupAvp);
						}
					}
				}
			}
		}

		// Second term in eqn 28. Compute non link likelihood. 
		if (currUser.nonFollowings != null) {
			for (int i = 0; i < currUser.nonFollowings.length; i++) {
				for (int p = 0; p < Configure.NUM_OF_PLATFORM; p++) {
					int v = currUser.nonFollowings[i].followingIndex;
					User nonFollowing = dataset.users[v];
					int nonFollowingPlatform = currUser.nonFollowings[i].platform;
					
					//only consider this user if he exist in the platform
					if (currUser.platforms[p] == 1){
						//only consider follower relationships in the platform
						if (nonFollowingPlatform == p){
							// Compute H_u^p * A_v^p
							double HupAvp = 0;
							for (int z = 0; z < nTopics; z++) {
								HupAvp += currUser.hubs[z] * x[z][p] * nonFollowing.authorities[z] * x[z][p];// now Eta_u,k is x
							}
							HupAvp = HupAvp * lamda;
							double fHupAvp = 2 * ((1 / (Math.exp(-HupAvp) + 1)) - 0.5); 
							nonLinkLikelihood += Math.log(fHupAvp);
						}
					}
				}
			}
		}
		if (currUser.nonFollowers != null) {
			for (int i = 0; i < currUser.nonFollowers.length; i++) {
				for (int p = 0; p < Configure.NUM_OF_PLATFORM; p++) {
					int v = currUser.nonFollowers[i].followerIndex;
					User nonFollower = dataset.users[v];
					int nonFollowerPlatform = currUser.nonFollowers[i].platform;
					
					//only consider this user if he exist in the platform
					if (currUser.platforms[p] == 1){
						//only consider follower relationships in the platform
						if (nonFollowerPlatform == p){
							// Compute H_u^p * A_v^p
							double HupAvp = 0;
							for (int z = 0; z < nTopics; z++) {
								HupAvp += nonFollower.hubs[z] * x[z][p] * currUser.authorities[z] * x[z][p];// now Eta_u,k is x
							}
							HupAvp = HupAvp * lamda;
							double fHupAvp = 2 * ((1 / (Math.exp(-HupAvp) + 1)) - 0.5); 
							nonLinkLikelihood += Math.log(fHupAvp);
						}
					}
				}
			}
		}
		
		// Third term in eqn 28. Compute post likelihood. 
		for (int s=0; s < currUser.nPosts; s++){
			int z = currUser.posts[s].topic;
			int currP = currUser.posts[s].platform;
			double denominator = 0;
			for (int p =0; p < Configure.NUM_OF_PLATFORM; p++){
				denominator += Math.exp(x[z][p]);
			}
			double nominator = Math.exp(x[z][currP]);
			postLikelihood += Math.log(nominator/denominator);			
		}
		
		// Fourth term in eqn 28. Compute platform likelihood.
		for (int p =0; p < Configure.NUM_OF_PLATFORM; p++){
			//platformLikelihood += 
		}
		
		
		
		return likelihood;
	}

	/***
	 * compute gradient of likelihood of data with respect to platform
	 * preference of u in topic k when the preference is x, i.e., if if
	 * L(data|parameters) = f(Eta_uk) + const-of-Eta_uk then this function
	 * return df/dEta_ukp at Eta_ukp = x
	 * 
	 * @param u
	 * @param k
	 * @param x
	 * @return
	 */
	private double gradLikelihood_platformPreference(int u, int k, double x) {
		// Refer to Eqn 30 in Learning paper
		return 0;

	}

	/***
	 * alternating step to optimize platform preference of user u for topic k
	 * 
	 * @param u
	 * @param k
	 */
	private void altOptimize_PlatformPreference(int u, int k) {
		// Tuan-Anh: we need this function to learn users' topic-specific
		// platform preference
	}
}
